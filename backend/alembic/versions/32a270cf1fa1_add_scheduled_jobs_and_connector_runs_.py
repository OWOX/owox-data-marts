"""Add scheduled jobs and connector runs tables

Revision ID: 32a270cf1fa1
Revises: 8cfc9bd2a80c
Create Date: 2025-09-29 14:30:27.755498

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '32a270cf1fa1'
down_revision = '8cfc9bd2a80c'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('connector_runs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('connector_id', sa.UUID(), nullable=False),
    sa.Column('scheduled_job_id', sa.UUID(), nullable=True),
    sa.Column('execution_id', sa.String(), nullable=False),
    sa.Column('trigger_type', sa.String(), nullable=False),
    sa.Column('status', sa.String(), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('duration_seconds', sa.Float(), nullable=True),
    sa.Column('records_transferred', sa.Integer(), nullable=True),
    sa.Column('success_rate', sa.Integer(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('source_collection_name', sa.String(), nullable=True),
    sa.Column('destination_name', sa.String(), nullable=True),
    sa.Column('destination_type', sa.String(), nullable=True),
    sa.Column('triggered_by_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['connector_id'], ['data_connectors.id'], ),
    sa.ForeignKeyConstraint(['scheduled_job_id'], ['scheduled_jobs.id'], ),
    sa.ForeignKeyConstraint(['triggered_by_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_connector_runs_connector_id'), 'connector_runs', ['connector_id'], unique=False)
    op.create_index(op.f('ix_connector_runs_execution_id'), 'connector_runs', ['execution_id'], unique=False)
    op.create_index(op.f('ix_connector_runs_id'), 'connector_runs', ['id'], unique=False)
    op.create_index(op.f('ix_connector_runs_scheduled_job_id'), 'connector_runs', ['scheduled_job_id'], unique=False)
    op.drop_index('ix_data_collections_id', table_name='data_collections')
    op.drop_table('data_collections')
    op.drop_table('analytics_data')
    op.add_column('scheduled_jobs', sa.Column('cron_expression', sa.String(), nullable=True))
    op.add_column('scheduled_jobs', sa.Column('interval_minutes', sa.Integer(), nullable=True))
    op.add_column('scheduled_jobs', sa.Column('last_run_at', sa.DateTime(timezone=True), nullable=True))
    op.add_column('scheduled_jobs', sa.Column('next_run_at', sa.DateTime(timezone=True), nullable=True))
    op.add_column('scheduled_jobs', sa.Column('last_run_status', sa.String(), nullable=True))
    op.add_column('scheduled_jobs', sa.Column('run_count', sa.Integer(), nullable=True))
    op.alter_column('scheduled_jobs', 'schedule_type',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('scheduled_jobs', 'schedule_config',
               existing_type=sa.TEXT(),
               type_=sa.JSON(),
               nullable=True)
    op.drop_column('scheduled_jobs', 'failure_count')
    op.drop_column('scheduled_jobs', 'next_execution_at')
    op.drop_column('scheduled_jobs', 'last_execution_at')
    op.drop_column('scheduled_jobs', 'execution_count')
    op.drop_column('scheduled_jobs', 'last_execution_status')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('scheduled_jobs', sa.Column('last_execution_status', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('scheduled_jobs', sa.Column('execution_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('scheduled_jobs', sa.Column('last_execution_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('scheduled_jobs', sa.Column('next_execution_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('scheduled_jobs', sa.Column('failure_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.alter_column('scheduled_jobs', 'schedule_config',
               existing_type=sa.JSON(),
               type_=sa.TEXT(),
               nullable=False)
    op.alter_column('scheduled_jobs', 'schedule_type',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.drop_column('scheduled_jobs', 'run_count')
    op.drop_column('scheduled_jobs', 'last_run_status')
    op.drop_column('scheduled_jobs', 'next_run_at')
    op.drop_column('scheduled_jobs', 'last_run_at')
    op.drop_column('scheduled_jobs', 'interval_minutes')
    op.drop_column('scheduled_jobs', 'cron_expression')
    op.create_table('analytics_data',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('campaign_id', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('campaign_name', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('date', sa.DATE(), autoincrement=False, nullable=True),
    sa.Column('impressions', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('clicks', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('cost', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=True),
    sa.Column('conversions', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('ctr', sa.NUMERIC(precision=5, scale=3), autoincrement=False, nullable=True),
    sa.Column('collection_id', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('transferred_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='analytics_data_pkey')
    )
    op.create_table('data_collections',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('data_mart_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('platform_credential_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('collection_name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('status', postgresql.ENUM('PENDING', 'RUNNING', 'SUCCESS', 'FAILED', 'CANCELLED', name='collectionstatus'), autoincrement=False, nullable=True),
    sa.Column('total_records', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('processed_records', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('failed_records', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('progress_percentage', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('started_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('error_details', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('collection_params', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('result_summary', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['data_mart_id'], ['data_marts.id'], name='data_collections_data_mart_id_fkey'),
    sa.ForeignKeyConstraint(['platform_credential_id'], ['platform_credentials.id'], name='data_collections_platform_credential_id_fkey'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='data_collections_user_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='data_collections_pkey')
    )
    op.create_index('ix_data_collections_id', 'data_collections', ['id'], unique=False)
    op.drop_index(op.f('ix_connector_runs_scheduled_job_id'), table_name='connector_runs')
    op.drop_index(op.f('ix_connector_runs_id'), table_name='connector_runs')
    op.drop_index(op.f('ix_connector_runs_execution_id'), table_name='connector_runs')
    op.drop_index(op.f('ix_connector_runs_connector_id'), table_name='connector_runs')
    op.drop_table('connector_runs')
    # ### end Alembic commands ###
